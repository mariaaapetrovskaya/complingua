{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariaaapetrovskaya/complingua/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22w2v_hw_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4SYal7iVHxA"
      },
      "source": [
        "В этом практикуме мы рассмотрим работу с библиотекой **Gensim** для работы с векторными представлениями текста\n",
        "\n",
        "Мы рассмотрим\n",
        "- **Word2Vec** - векторные представления слов\n",
        "- **FastText** - улучшенные представления с учетом морфологии  \n",
        "- **Doc2Vec** - векторные представления документов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bolJ-w-oVVZZ",
        "outputId": "0df70791-f490-4b26-90d6-7f661aec75b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec, FastText, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB663h2uXJE7"
      },
      "source": [
        "## Часть 1: Word2Vec\n",
        "\n",
        "### Что такое Word2Vec?\n",
        "\n",
        "Word2Vec преобразует слова в векторы чисел так, что семантически похожие слова оказываются близко в векторном пространстве.\n",
        "\n",
        "**Два основных алгоритма:**\n",
        "- **CBOW** - предсказывает слово по контексту\n",
        "- **Skip-gram** - предсказывает контекст по слову\n",
        "\n",
        "**Загрузка предобученной модели**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m2YjiqkVVmd",
        "outputId": "8b51910d-54a6-4c0a-ce5d-eeed89f6a340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря: 400000\n",
            "Размерность векторов: 100\n"
          ]
        }
      ],
      "source": [
        "w2v_model = api.load('glove-wiki-gigaword-100')\n",
        "\n",
        "print(f\"Размер словаря: {len(w2v_model.key_to_index)}\")\n",
        "print(f\"Размерность векторов: {w2v_model.vector_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDOPbPZCXQJJ"
      },
      "source": [
        "Найдите документацию `gensim`: какие датасеты кроме `glove-wiki-gigaword-100` доступны в библиотеке?\n",
        "\n",
        "Выберите 3 датасета и кратко опишите их (источник данных, примерный объем, зачем такой датасет может использоваться)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eib9fIpIXp3H"
      },
      "source": [
        "**Базовые операции с векторами**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9fBjDYNXoUO",
        "outputId": "4aadfc99-e322-4197-ae1a-57400e6eac05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор слова 'computer': [-0.16298   0.30141   0.57978   0.066548  0.45835 ]...\n",
            "Схожесть 'computer' и 'laptop': 0.7024\n"
          ]
        }
      ],
      "source": [
        "# Получаем вектор слова\n",
        "vector = w2v_model['computer']\n",
        "print(f\"Вектор слова 'computer': {vector[:5]}...\")  # Показываем первые 5 чисел\n",
        "\n",
        "# Вычисляем схожесть между словами\n",
        "similarity = w2v_model.similarity('computer', 'laptop')\n",
        "print(f\"Схожесть 'computer' и 'laptop': {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev1yMPZ8XuI3"
      },
      "source": [
        "**Поиск похожих слов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WkxOy8uXteF",
        "outputId": "641301c6-bc91-46fc-df64-addb660d1034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'python':\n",
            "  monty: 0.6886\n",
            "  php: 0.5865\n",
            "  perl: 0.5784\n",
            "  cleese: 0.5447\n",
            "  flipper: 0.5113\n"
          ]
        }
      ],
      "source": [
        "# Находим похожие слова\n",
        "similar_words = w2v_model.most_similar('python', topn=5)\n",
        "print(\"Слова, похожие на 'python':\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"  {word}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKeYJM6IXgVQ"
      },
      "source": [
        "**Первый датасет/модель - fake-news. **\n",
        "Модель обучена на на датасете фейковых новостей. Размер файлов - 19 MB, содержит текст и метаданные с 244 веб-сайтов (в общей сложности 12 999 сообщений за определенный период в 30 дней). Ее сожно использовать, например, для анализ стиля текстов, для классификации именно фейковыйх новостей и т.д. Ссылка: https://www.kaggle.com/mrisdal/fake-news\n",
        "**Вторая модель - word2vec-ruscorpora-300.** Ее объем - 198 MB. Она обучена на Русском Национальном Корпусе(около  250M слов). 184973 векторов. Это именно русскоязычная модель, она обучена на разных текстах (художественная литература, новости, научные статьи). Может быть использована для обработки русского текста. Ссылки: https://www.academia.edu/24306935/WebVectors_a_Toolkit_for_Building_Web_Interfaces_for_Vector_Semantic_Models\n",
        "http://rusvectores.org/en/\n",
        "**Третья - glove-twitter-100. **\n",
        "1193514 векторов. Объем файлов - 387 MB. Содержит тексты из Twitterа (2B tweets, 27B tokens, 1.2M vocab, uncased). Компактная модель, она хорошо работает с разными сокращениями, хештегами и сленгом (для анализа подобных текстов ее и можно использовать). Ссылки: https://nlp.stanford.edu/projects/glove/\n",
        "https://nlp.stanford.edu/pubs/glove.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM76pHnKXi_K"
      },
      "source": [
        "**Задание**\n",
        "\n",
        "1. Загрузите любой датасет из gensim на ваш выбор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqblXXpmXOhi",
        "outputId": "2691422f-93de-41bf-9ca9-673bd28b7a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n",
            "Размер словаря: 1193514\n",
            "Размерность векторов: 100\n"
          ]
        }
      ],
      "source": [
        "w2v_model = api.load('glove-twitter-100')\n",
        "print(f\"Размер словаря: {len(w2v_model.key_to_index)}\")\n",
        "print(f\"Размерность векторов: {w2v_model.vector_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr2jwkoYXw4t"
      },
      "source": [
        "2. Напишите функцию, которая принимает на вход любое слово и вовращает 10 наиболее близких по вектору слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "41PPnrrtX7lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc784a5-f618-4bbd-8877-e5ea262e709d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "обычные слова\n",
            "Наиболее близкие слова для слова 'apple':\n",
            "  microsoft: 0.823\n",
            "  samsung: 0.779\n",
            "  iphone: 0.767\n",
            "  google: 0.762\n",
            "  nokia: 0.749\n",
            "  blackberry: 0.741\n",
            "  nexus: 0.741\n",
            "  ipad: 0.737\n",
            "  galaxy: 0.729\n",
            "  smartphone: 0.719\n",
            "\n",
            "==================================================\n",
            "сленг\n",
            "Наиболее близкие слова для слова 'lol':\n",
            "  lmao: 0.917\n",
            "  lmfao: 0.870\n",
            "  yeah: 0.854\n",
            "  lolol: 0.854\n",
            "  aha: 0.848\n",
            "  wtf: 0.847\n",
            "  thats: 0.845\n",
            "  dude: 0.843\n",
            "  but: 0.839\n",
            "  shit: 0.834\n",
            "\n",
            "==================================================\n",
            "хештеги\n",
            "Наиболее близкие слова для слова '#health':\n",
            "  #fitness: 0.704\n",
            "  #motivation: 0.550\n",
            "  #weightloss: 0.549\n",
            "  #shape: 0.537\n",
            "  #workout: 0.520\n",
            "  #shopping: 0.498\n",
            "  #training: 0.474\n",
            "  наблюдаю: 0.474\n",
            "  kuranla: 0.474\n",
            "  hiddet: 0.466\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def find_similar_words(word, topn=10):\n",
        "    print(f\"Наиболее близкие слова для слова '{word}':\")\n",
        "\n",
        "    try:\n",
        "        similar_words = w2v_model.most_similar(word, topn=topn)\n",
        "        for similar_word, score in similar_words:\n",
        "            print(f\"  {similar_word}: {score:.3f}\")\n",
        "    except KeyError:\n",
        "        print(f\"  Слово '{word}' не найдено в модели\")\n",
        "\n",
        "# Тестируем функцию с разными типами слов\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"обычные слова\")\n",
        "find_similar_words(\"apple\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"сленг\")\n",
        "find_similar_words(\"lol\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"хештеги\")\n",
        "find_similar_words(\"#health\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqb9gAAtX-2e"
      },
      "source": [
        "3. Обучите модель Word2Vec на тестовом датасете из ячейки ниже\n",
        "\n",
        "Примените следующие настройки:\n",
        "\n",
        "- размер вектора: 50\n",
        "- размер окна: 3\n",
        "- минимальная частота слова: 1\n",
        "- потоков: 2\n",
        "- использовать skip-gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Hx2_76jlX99p"
      },
      "outputs": [],
      "source": [
        "cooking_sentences = [\n",
        "    ['варить', 'суп', 'овощи', 'морковь', 'картофель'],\n",
        "    ['жарить', 'курица', 'сковорода', 'масло', 'специи'],\n",
        "    ['печь', 'хлеб', 'мука', 'дрожжи', 'духовка'],\n",
        "    ['резать', 'овощи', 'салат', 'помидоры', 'огурцы'],\n",
        "    ['смешивать', 'ингредиенты', 'тесто', 'яйца', 'молоко'],\n",
        "    ['варить', 'паста', 'вода', 'соль', 'соус'],\n",
        "    ['гриль', 'мясо', 'овощи', 'уголь', 'барбекю'],\n",
        "    ['тушить', 'говядина', 'горшок', 'вино', 'травы'],\n",
        "    ['запекать', 'рыба', 'лимон', 'духовка', 'фольга'],\n",
        "    ['готовить', 'завтрак', 'яичница', 'бекон', 'тост'],\n",
        "    ['месить', 'тесто', 'пирог', 'начинка', 'яблоки'],\n",
        "    ['кипятить', 'вода', 'чай', 'кофе', 'чашка'],\n",
        "    ['мариновать', 'мясо', 'соус', 'специи', 'холодильник'],\n",
        "    ['взбивать', 'сливки', 'сахар', 'десерт', 'торт'],\n",
        "    ['парить', 'овощи', 'здоровое', 'питание', 'брокколи']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-ql25a3lYIWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d33b6ec-e55c-4bb2-97a2-df4df5672f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова в словаре: ['овощи', 'мясо', 'соус', 'вода', 'тесто', 'духовка', 'специи', 'варить', 'брокколи', 'питание']...\n",
            "Слова, похожие на 'паста':\n",
            "  сахар: 0.2804\n",
            "  горшок: 0.2443\n",
            "  тушить: 0.2439\n",
            "  говядина: 0.2105\n",
            "  суп: 0.1926\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(\n",
        "    sentences=cooking_sentences,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2,\n",
        "    sg=1\n",
        ")\n",
        "\n",
        "print(f\"Слова в словаре: {list(model.wv.key_to_index.keys())[:10]}...\")\n",
        "\n",
        "try:\n",
        "    similar = model.wv.most_similar('паста', topn=5)\n",
        "    print(\"Слова, похожие на 'паста':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'паста' не найдено в словаре\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUp76Ko3YYLi"
      },
      "source": [
        "4. Проверьте модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NL21ZMMMYZqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71b8415-d7f8-4737-ec5a-a2d63ed9a570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'варить':\n",
            "  вино: 0.2398\n",
            "  ингредиенты: 0.2172\n",
            "  хлеб: 0.1938\n",
            "  брокколи: 0.1846\n",
            "  кипятить: 0.1711\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "    similar = model.wv.most_similar('варить', topn=5)\n",
        "    print(\"Слова, похожие на 'варить':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'варить' не найдено в словаре\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DZWc7eNVYcSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66eada3-86c1-4335-b9d3-f591b139b2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'духовка':\n",
            "  ингредиенты: 0.3199\n",
            "  десерт: 0.3064\n",
            "  холодильник: 0.2705\n",
            "  питание: 0.2243\n",
            "  пирог: 0.2142\n",
            "Слова, похожие на 'овощи':\n",
            "  мариновать: 0.2716\n",
            "  хлеб: 0.2691\n",
            "  гриль: 0.2546\n",
            "  фольга: 0.2409\n",
            "  сахар: 0.2108\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "    similar = model.wv.most_similar('духовка', topn=5)\n",
        "    print(\"Слова, похожие на 'духовка':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'духовка' не найдено в словаре\")\n",
        "\n",
        "try:\n",
        "    similar = model.wv.most_similar('овощи', topn=5)\n",
        "    print(\"Слова, похожие на 'овощи':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'овощи' не найдено в словаре\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1JAFNQvYhAz"
      },
      "source": [
        "## Часть 2: FastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1tWdzB-Ysi9"
      },
      "source": [
        "FastText улучшает Word2Vec, рассматривая слова как наборы символов (n-грамм). Это позволяет работать с редкими словами и опечатками"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79i4vH8NY-0G"
      },
      "source": [
        "5. Обучите FastText на корпусе текстов из пункта 3. Используйте код ниже"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-IrOgMpQYuda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0299c8a9-8e76-414f-89bf-372dfbeb0305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова в словаре FastText: ['овощи', 'мясо', 'соус', 'вода', 'тесто', 'духовка', 'специи', 'варить', 'брокколи', 'питание']...\n"
          ]
        }
      ],
      "source": [
        "ft_model = FastText(\n",
        "    sentences=cooking_sentences,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "print(f\"Слова в словаре FastText: {list(ft_model.wv.key_to_index.keys())[:10]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBTW3zDPZIIk"
      },
      "source": [
        "6. Найдите слова, похожие на \"варить\", \"духовка\" и \"овощи\" с помощью обученной модели. Используйте код из пункта 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ouc0CcZAY6QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1257f5-d159-4839-b982-b1ddbf685224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Слова, похожие на 'варить':\n",
            "  жарить: 0.5353\n",
            "  парить: 0.4805\n",
            "  месить: 0.3541\n",
            "  тушить: 0.3405\n",
            "  специи: 0.2622\n",
            "\n",
            "==================================================\n",
            "Слова, похожие на 'духовка':\n",
            "  взбивать: 0.4565\n",
            "  лимон: 0.3561\n",
            "  салат: 0.3050\n",
            "  курица: 0.3041\n",
            "  тост: 0.2944\n",
            "\n",
            "==================================================\n",
            "Слова, похожие на 'овощи':\n",
            "  жарить: 0.2960\n",
            "  фольга: 0.2574\n",
            "  морковь: 0.2297\n",
            "  соус: 0.2172\n",
            "  торт: 0.2094\n"
          ]
        }
      ],
      "source": [
        "test_words = ['варить', 'духовка', 'овощи']\n",
        "\n",
        "for word in test_words:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Слова, похожие на '{word}':\")\n",
        "\n",
        "    try:\n",
        "        similar_words = ft_model.wv.most_similar(word, topn=5)\n",
        "        for similar_word, score in similar_words:\n",
        "            print(f\"  {similar_word}: {score:.4f}\")\n",
        "    except KeyError:\n",
        "        print(f\"  Слово '{word}' не найдено в модели\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm8kkRlBZYc2"
      },
      "source": [
        "7. Сравните модели\n",
        "\n",
        "Дана функция для сравнения Word2Vec и FastText\n",
        "\n",
        "Придумайте 3 слова с опечатками и проверьте, найдет ли их FastText и Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3nVH_v9WZY4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d595d7a7-b434-41ea-ee8f-8d3a65435755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Сравнение Word2Vec и FastText для слов из корпуса:\n",
            "============================================================\n",
            "\n",
            "Сравнение для слова: 'варить'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['жарить', 'парить']\n",
            "\n",
            "Сравнение для слова: 'духовка'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['взбивать', 'лимон']\n",
            "\n",
            "Сравнение для слова: 'овощи'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['жарить', 'фольга']\n",
            "\n",
            "Сравнение для слова: 'паста'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['хлеб', 'печь']\n"
          ]
        }
      ],
      "source": [
        "def compare_models(word):\n",
        "    \"\"\"Сравнивает представления слова в разных моделях\"\"\"\n",
        "    print(f\"\\nСравнение для слова: '{word}'\")\n",
        "\n",
        "    try:\n",
        "        w2v_similar = model.wv.most_similar(word, topn=2)\n",
        "        print(f\"  Word2Vec: {[w for w, _ in w2v_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  Word2Vec: слово не найдено\")\n",
        "\n",
        "    try:\n",
        "        ft_similar = ft_model.wv.most_similar(word, topn=2)\n",
        "        print(f\"  FastText: {[w for w, _ in ft_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText: слово не найдено\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Сравнение Word2Vec и FastText для слов из корпуса:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "compare_models('варить')\n",
        "compare_models('духовка')\n",
        "compare_models('овощи')\n",
        "compare_models('паста')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP62ewZzZoGo"
      },
      "source": [
        "## Часть 3: Doc2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG1GNzXcZqOY"
      },
      "source": [
        "Doc2Vec расширяет Word2Vec для создания векторных представлений целых документов (предложений, абзацев, статей)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_85mtFa_ZxoY",
        "outputId": "70f0884b-552a-4c08-e212-c533c26a17df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеченные документы:\n",
            "  Слова: ['machine', 'learning', 'is', 'interesting']\n",
            "  Тег: ['doc_0']\n",
            "  Слова: ['deep', 'learning', 'uses', 'neural', 'networks']\n",
            "  Тег: ['doc_1']\n",
            "  Слова: ['python', 'programming', 'for', 'data', 'science']\n",
            "  Тег: ['doc_2']\n"
          ]
        }
      ],
      "source": [
        "# Создаем размеченные документы\n",
        "documents = [\n",
        "    \"machine learning is interesting\",\n",
        "    \"deep learning uses neural networks\",\n",
        "    \"python programming for data science\",\n",
        "    \"artificial intelligence is amazing\",\n",
        "    \"computer vision processes images\"\n",
        "]\n",
        "\n",
        "# Преобразуем в формат TaggedDocument\n",
        "tagged_docs = []\n",
        "for i, doc in enumerate(documents):\n",
        "    tokens = doc.split()\n",
        "    tagged_doc = TaggedDocument(words=tokens, tags=[f\"doc_{i}\"])\n",
        "    tagged_docs.append(tagged_doc)\n",
        "\n",
        "print(\"Размеченные документы:\")\n",
        "for doc in tagged_docs[:3]:\n",
        "    print(f\"  Слова: {doc.words}\")\n",
        "    print(f\"  Тег: {doc.tags}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HJ1vOcHZx0z",
        "outputId": "217cd801-8113-4a76-b8a4-c4922ffab4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc2Vec модель обучена!\n",
            "Количество документов: 5\n"
          ]
        }
      ],
      "source": [
        "# Обучаем Doc2Vec\n",
        "doc_model = Doc2Vec(\n",
        "    documents=tagged_docs,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "print(\"Doc2Vec модель обучена!\")\n",
        "print(f\"Количество документов: {len(doc_model.dv.key_to_index)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x8vHn0bZ0Ow",
        "outputId": "a8d8b895-f60b-4ca6-e5bb-83831ad703f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор документа doc_0: [-0.01057    -0.01198188 -0.01982618  0.01710627  0.00710373]...\n",
            "\n",
            "Документы, похожие на doc_0:\n",
            "  doc_1: 0.2735\n",
            "    Текст: deep learning uses neural networks\n",
            "  doc_2: 0.1275\n",
            "    Текст: python programming for data science\n"
          ]
        }
      ],
      "source": [
        "# Получаем вектор документа\n",
        "doc_vector = doc_model.dv[\"doc_0\"]\n",
        "print(f\"Вектор документа doc_0: {doc_vector[:5]}...\")\n",
        "\n",
        "# Находим похожие документы\n",
        "similar_docs = doc_model.dv.most_similar(\"doc_0\", topn=2)\n",
        "print(\"\\nДокументы, похожие на doc_0:\")\n",
        "for doc_tag, similarity in similar_docs:\n",
        "    doc_id = int(doc_tag.split('_')[1])\n",
        "    print(f\"  {doc_tag}: {similarity:.4f}\")\n",
        "    print(f\"    Текст: {documents[doc_id]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfjR2xZZ1rC",
        "outputId": "ec6313df-8b8d-4900-c865-f4abdd33114d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_0 и doc_1: 0.2735\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_1: deep learning uses neural networks\n",
            "Схожесть doc_0 и doc_3: -0.0822\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_3: artificial intelligence is amazing\n"
          ]
        }
      ],
      "source": [
        "# Сравниваем схожесть документов\n",
        "def compare_documents(doc1_id, doc2_id):\n",
        "    similarity = doc_model.dv.similarity(f\"doc_{doc1_id}\", f\"doc_{doc2_id}\")\n",
        "    print(f\"Схожесть doc_{doc1_id} и doc_{doc2_id}: {similarity:.4f}\")\n",
        "    print(f\"  doc_{doc1_id}: {documents[doc1_id]}\")\n",
        "    print(f\"  doc_{doc2_id}: {documents[doc2_id]}\")\n",
        "\n",
        "compare_documents(0, 1)  # machine learning vs deep learning\n",
        "compare_documents(0, 3)  # machine learning vs AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ruGP7-vZ6HS"
      },
      "source": [
        "8. Сравните схожесть doc_2 и doc_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LujlVE8aZ3fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4959ea-b602-44e3-b640-5bf5f6786973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_2 и doc_4: -0.0362\n",
            "  doc_2: python programming for data science\n",
            "  doc_4: computer vision processes images\n"
          ]
        }
      ],
      "source": [
        "compare_documents(2, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkW4U8T_Z_X_"
      },
      "source": [
        "9. Найдите самый похожий документ на doc_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "T0IwRpOPaGX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f463b1d8-344d-46af-ec56-3f5023f314d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сортир. по схожести с doc_1:\n",
            "  doc_0: 0.2735 - machine learning is interesting\n",
            "  doc_3: 0.2031 - artificial intelligence is amazing\n",
            "  doc_2: -0.0573 - python programming for data science\n",
            "  doc_4: -0.2546 - computer vision processes images\n",
            "\n",
            "Самый похожий документ на doc_1:\n",
            "  doc_0: 0.2735\n",
            "  Текст: machine learning is interesting\n"
          ]
        }
      ],
      "source": [
        "similar_to_1 = doc_model.dv.most_similar(\"doc_1\", topn=len(doc_model.dv.key_to_index))\n",
        "print(\"Сортир. по схожести с doc_1:\")\n",
        "for doc_tag, similarity in similar_to_1:\n",
        "    doc_id = int(doc_tag.split('_')[1])\n",
        "    print(f\"  {doc_tag}: {similarity:.4f} - {documents[doc_id]}\")\n",
        "\n",
        "# Самый похожий документ на doc_1\n",
        "most_similar_doc = similar_to_1[0]\n",
        "print(f\"\\nСамый похожий документ на doc_1:\")\n",
        "print(f\"  {most_similar_doc[0]}: {most_similar_doc[1]:.4f}\")\n",
        "doc_id = int(most_similar_doc[0].split('_')[1])\n",
        "print(f\"  Текст: {documents[doc_id]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHoOQmGraGmC"
      },
      "source": [
        "10. Выберите любую из трёх моделей. Обучите модели с разной размерностью (10, 50, 100). Продемонстрируйте качество их работы на примере поиска похожих слов (выберите любые 3 примера, соответствующих тематике корпуса из пункта 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tidpF7AIaXzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7076509d-e76e-44bf-b501-ebd160de3de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "обучение модели vector_size=10...\n",
            "  Размер словаря: 25967\n",
            "\n",
            "обучение модели vector_size=50...\n",
            "  Размер словаря: 25967\n",
            "\n",
            "обучение модели vector_size=100...\n",
            "  Размер словаря: 25967\n",
            "\n",
            "============================================================\n",
            "Сравнение качества моделей:\n",
            "============================================================\n",
            "\n",
            "Похожие слова для 'user':\n",
            "\n",
            "  vector_size=10:\n",
            "    conformed: 0.999\n",
            "    bulky: 0.997\n",
            "    affinity: 0.997\n",
            "\n",
            "  vector_size=50:\n",
            "    intentional: 0.997\n",
            "    traced: 0.997\n",
            "    validity: 0.996\n",
            "\n",
            "  vector_size=100:\n",
            "    phonologic: 0.998\n",
            "    kohnstammnegative: 0.998\n",
            "    diagrams: 0.998\n",
            "\n",
            "Похожие слова для 'government':\n",
            "\n",
            "  vector_size=10:\n",
            "    union: 0.977\n",
            "    court: 0.959\n",
            "    aid: 0.957\n",
            "\n",
            "  vector_size=50:\n",
            "    foreign: 0.963\n",
            "    union: 0.961\n",
            "    federal: 0.958\n",
            "\n",
            "  vector_size=100:\n",
            "    foreign: 0.977\n",
            "    federal: 0.976\n",
            "    union: 0.966\n",
            "\n",
            "Похожие слова для 'congress':\n",
            "\n",
            "  vector_size=10:\n",
            "    court: 0.964\n",
            "    report: 0.961\n",
            "    representatives: 0.959\n",
            "\n",
            "  vector_size=50:\n",
            "    supreme: 0.970\n",
            "    constitution: 0.961\n",
            "    soviet: 0.951\n",
            "\n",
            "  vector_size=100:\n",
            "    supreme: 0.972\n",
            "    america: 0.969\n",
            "    court: 0.968\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "import string\n",
        "\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "\n",
        "sentences = brown.sents()\n",
        "\n",
        "def preprocess_text(sentences, sample_size=10000):\n",
        "    processed_sentences = []\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    for sentence in sentences[:sample_size]:\n",
        "        cleaned = [word.lower().translate(translator) for word in sentence]\n",
        "        words = [word for word in cleaned if word.isalpha() and len(word) > 1]\n",
        "        if len(words) >= 3:\n",
        "            processed_sentences.append(words)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "\n",
        "def remove_stopwords(sentences):\n",
        "    from nltk.corpus import stopwords\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    processed_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        filtered_sentence = [word for word in sentence if word not in stop_words]\n",
        "        processed_sentences.append(filtered_sentence)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "\n",
        "processed_sentences = preprocess_text(sentences, sample_size=55000)\n",
        "sentences_without_stopwords = remove_stopwords(processed_sentences)\n",
        "\n",
        "\n",
        "test_words = ['user', 'government', 'congress']\n",
        "vector_sizes = [10, 50, 100]\n",
        "models = {}\n",
        "\n",
        "for vs in vector_sizes:\n",
        "    print(f\"\\nобучение модели vector_size={vs}...\")\n",
        "    model = Word2Vec(\n",
        "        sentences=sentences_without_stopwords,\n",
        "        vector_size=vs,\n",
        "        window=3,\n",
        "        min_count=2,\n",
        "        workers=4,\n",
        "        sg=1\n",
        "    )\n",
        "    models[vs] = model\n",
        "    print(f\"  Размер словаря: {len(model.wv.key_to_index)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Сравнение качества моделей:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for word in test_words:\n",
        "    print(f\"\\nПохожие слова для '{word}':\")\n",
        "\n",
        "    for vs in vector_sizes:\n",
        "        print(f\"\\n  vector_size={vs}:\")\n",
        "        try:\n",
        "            similar_words = models[vs].wv.most_similar(word, topn=3)\n",
        "            for similar_word, score in similar_words:\n",
        "                print(f\"    {similar_word}: {score:.3f}\")\n",
        "        except KeyError:\n",
        "            print(f\"    Слово '{word}' не найдено в модели\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}